# Code of Conduct - AI Intelligence Explosion Detection Red Team

## üéØ Our Mission

We are committed to creating an open, welcoming, and safe environment for all contributors working on AI safety research. Our mission is to detect and prevent dangerous AI capabilities while fostering a collaborative global community.

## ü§ù Our Pledge

In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of:

- Age, body size, disability, ethnicity, gender identity and expression
- Level of experience, education, socio-economic status
- Nationality, personal appearance, race, religion
- Sexual identity and orientation
- Technical background or area of expertise

## ‚úÖ Our Standards

### Examples of behavior that contributes to creating a positive environment:

**ü§ñ AI Safety Focus**
- Prioritizing human safety and well-being in all research
- Conducting responsible research with appropriate safeguards
- Sharing findings openly while minimizing dual-use risks
- Collaborating internationally for global AI safety

**ü§ù Professional Conduct**
- Using welcoming and inclusive language
- Being respectful of differing viewpoints and experiences
- Gracefully accepting constructive criticism
- Focusing on what is best for the community and humanity
- Showing empathy towards other community members

**üî¨ Research Excellence**
- Maintaining scientific rigor and integrity
- Documenting methodology clearly and transparently
- Acknowledging limitations and uncertainties
- Citing and crediting others' work appropriately

**üõ°Ô∏è Security Mindset**
- Following responsible disclosure practices
- Protecting sensitive information appropriately
- Considering security implications of all contributions
- Reporting vulnerabilities through proper channels

### Examples of unacceptable behavior:

**üö´ Harmful Research Practices**
- Developing or sharing actual harmful AI capabilities
- Conducting research without appropriate safety measures
- Ignoring potential dual-use implications
- Withholding critical safety information

**üö´ Unprofessional Conduct**
- The use of sexualized language or imagery and unwelcome sexual attention or advances
- Trolling, insulting/derogatory comments, and personal or political attacks
- Public or private harassment
- Publishing others' private information without explicit permission
- Other conduct which could reasonably be considered inappropriate in a professional setting

**üö´ Academic Misconduct**
- Plagiarism or misrepresentation of others' work
- Falsifying or fabricating research results
- Violating research ethics or safety protocols
- Misusing institutional affiliations or credentials

## üõ°Ô∏è Special Considerations for AI Safety Research

### Responsible AI Research Practices

1. **Safety First**
   - All research must prioritize human safety and well-being
   - Never create or test actually dangerous AI capabilities
   - Use appropriate containment and safety measures

2. **Dual-Use Awareness**
   - Consider how research could be misused
   - Implement appropriate information sharing controls
   - Coordinate with relevant authorities when necessary

3. **Ethical Boundaries**
   - Respect human dignity and rights
   - Avoid research that could cause psychological harm
   - Consider societal implications of findings

4. **Transparency vs. Security**
   - Balance open science with security concerns
   - Use appropriate channels for sensitive information
   - Document safety rationale for disclosure decisions

### Security and Privacy

1. **Information Handling**
   - Protect personally identifiable information
   - Secure sensitive research data appropriately
   - Follow organizational and legal requirements

2. **Responsible Disclosure**
   - Report vulnerabilities through established channels
   - Coordinate disclosure timing appropriately
   - Consider impact on affected parties

## üìã Our Responsibilities

### Project Maintainers

Project maintainers are responsible for:

- Clarifying standards of acceptable behavior
- Taking appropriate and fair corrective action in response to unacceptable behavior
- Reviewing and moderating contributions for safety and quality
- Coordinating with relevant authorities for security issues
- Maintaining the technical and ethical integrity of the project

### Community Members

All community members are responsible for:

- Following this code of conduct
- Reporting unacceptable behavior
- Supporting a positive community environment
- Maintaining professional standards in all interactions
- Prioritizing AI safety and human welfare

## üö® Enforcement

### Reporting Process

Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by:

1. **Standard Issues**: GitHub issue or discussion
2. **Behavioral Concerns**: conduct@ai-redteam.org
3. **Security Issues**: security@ai-redteam.org
4. **Anonymous Reports**: [Anonymous form link]

### What to Include in Reports

Please provide as much information as possible:

- Description of the incident
- Individuals involved (if known)
- When and where it occurred
- Any supporting documentation
- Impact on you or others
- Desired resolution (if any)

### Investigation Process

1. **Acknowledgment**: We will acknowledge receipt within 24 hours
2. **Investigation**: Thorough and impartial investigation
3. **Resolution**: Appropriate corrective action
4. **Follow-up**: Monitoring to ensure resolution effectiveness

### Enforcement Guidelines

**Level 1: Warning**
- First-time minor violations
- Clear explanation of inappropriate behavior
- Expectation of immediate behavior change

**Level 2: Temporary Restriction**
- Repeated or more serious violations
- Temporary suspension from certain community activities
- Specific conditions for reinstatement

**Level 3: Permanent Ban**
- Severe or repeated violations
- Permanent removal from all community activities
- Public notification if appropriate for safety

**Special Cases: Security Violations**
- Immediate temporary restrictions pending investigation
- Coordination with relevant authorities if necessary
- Potential legal action for severe violations

## üîÑ Appeals Process

If you believe enforcement action was taken in error:

1. **Submit Appeal**: appeals@ai-redteam.org within 30 days
2. **Review**: Independent review by different maintainers
3. **Decision**: Final decision within 14 days
4. **Implementation**: Immediate implementation of appeal decision

## üåç International Considerations

Given our global mission:

### Cultural Sensitivity
- Respect diverse cultural backgrounds and perspectives
- Be aware of different communication styles
- Consider time zones and languages in coordination

### Legal Compliance
- Follow applicable laws in all jurisdictions
- Respect international AI governance frameworks
- Coordinate with relevant national authorities

### Collaborative Standards
- Align with international AI safety community standards
- Participate in global coordination efforts
- Share learnings with international partners

## üìö Resources and Support

### AI Safety Resources
- [AI Safety Fundamentals](https://aisafetyfundamentals.com/)
- [Future of Humanity Institute](https://www.fhi.ox.ac.uk/)
- [Machine Intelligence Research Institute](https://intelligence.org/)

### Professional Development
- Conference speaking opportunities
- Research collaboration
- Mentorship programs

### Mental Health Support
AI safety research can be emotionally challenging:
- Take breaks when needed
- Seek support from community members
- Access professional mental health resources

## üìû Contact Information

- **General Conduct**: conduct@ai-redteam.org
- **Security Issues**: security@ai-redteam.org  
- **Appeals**: appeals@ai-redteam.org
- **Anonymous Reports**: [Secure form link]
- **Emergency Contact**: +1-XXX-XXX-XXXX (24/7)

## üîÑ Updates

This Code of Conduct may be updated to:
- Reflect evolving AI safety best practices
- Address new types of research challenges
- Incorporate community feedback
- Align with international standards

**Version**: 1.0  
**Last Updated**: December 2024  
**Next Review**: June 2025

---

## ü§ù Acknowledgments

This code of conduct is adapted from:
- [Contributor Covenant](https://www.contributor-covenant.org/), version 2.0
- AI safety research community best practices
- International AI governance frameworks

**Together, we can make AI systems safer for everyone.** ü§ñüõ°Ô∏è
